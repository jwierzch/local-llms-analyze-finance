{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37273e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#thanks this is ripped from https://github.com/thu-vu92/local-llms-analyse-finance/blob/main/categorize_expenses_with_validation.ipynb\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "debugging=1\n",
    "if debugging:\n",
    "    file_path = 'd_out.txt'\n",
    "    f = open(file_path,'w')\n",
    "    f.write(\"dubug log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aa58f17-bfef-4369-9c67-e801f10a4a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "directory = './transactions/'\n",
    "transfiles = [directory+f for f in listdir(directory) if isfile(join(directory, f))]\n",
    "skip_list=['checking','savings']\n",
    "\n",
    "cc_files=[f for f in transfiles if all(skip not in f for skip in skip_list) and 'lock' not in f]\n",
    "if debugging: f.write(','.join(cc_files))\n",
    "    \n",
    "acc_files = [join(directory, f) for f in listdir(directory) \n",
    "         if os.path.isfile(os.path.join(directory, f)) and (f.startswith('checking') or f.startswith('savings'))]\n",
    "if debugging: f.write(','.join(acc_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfa55c22-e89d-453a-95c1-d963efcbf9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cc_transactions(transfile):\n",
    "    df = pd.read_csv(transfile)\n",
    "    df['account']=transfile.split('_')[1].split('.')[0]\n",
    "    df['fname']=transfile.split('/')[2].split('.')[0]\n",
    "    df = df.rename(columns={'Payee': 'Description', 'Posted Date':'Date'})\n",
    "    \n",
    "    #https://www.statology.org/pandas-remove-special-characters/\n",
    "    pattern = r'[^\\w\\s]'\n",
    "    df['Description'] = df['Description'].str.replace(pattern, '', regex=True)\n",
    "    df['Description'] = df['Description'].str.replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9893e851-71e1-44be-a70f-75b161ea21a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_acc_transactions(transfile):\n",
    "    df = pd.read_csv(transfile, delimiter=',')\n",
    "    df['account']=transfile.split('_')[1].split('.')[0]\n",
    "    df['fname']=transfile.split('/')[2].split('.')[0]\n",
    "    #\n",
    "    if (np.isin([True], df.columns.str.contains('^Unnamed'))):\n",
    "        df.rename( columns={'Unnamed: 4':'bastard'}, inplace=True )\n",
    "        mask = df[\"bastard\"].isna() \n",
    "        df.loc[~mask, \"Amount\"] = df.loc[~mask, \"Running Bal.\"]\n",
    "        df.drop(columns=['bastard'], inplace=True)\n",
    "        df.dropna(inplace=True)\n",
    "\n",
    "    df\n",
    "    \n",
    "    \n",
    "    df.drop(columns=['Running Bal.'], inplace=True)\n",
    "    df['Amount'] = df['Amount'].astype(float)\n",
    "    # create a new column 'hashed' as a hash of columns 'A' and 'B'\n",
    "    df['Reference Number'] = df.apply((lambda x: str(hash(str(df['Date'])+str(df['Description'])+str(df['Amount'])+str(df['account'])))), axis=1)\n",
    "\n",
    "    #https://www.statology.org/pandas-remove-special-characters/\n",
    "    pattern = r'[^\\w\\s]'\n",
    "    df['Description'] = df['Description'].str.replace(pattern, '', regex=True)\n",
    "    df['Description'] = df['Description'].str.replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "342c5d05-59e2-4219-9e0d-b8bef044f30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_transframes=[]\n",
    "if cc_files:\n",
    "    for cc_file in cc_files[1:]:\n",
    "        cc_transframes.append(read_cc_transactions(cc_file))\n",
    "    cc_trans=pd.concat(cc_transframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f7a371a-fa02-437d-ba39-ffe48a5b1c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_transframes=[]\n",
    "if acc_files:\n",
    "    for acc_file in acc_files[1:]:\n",
    "        acc_transframes.append(read_acc_transactions(acc_file))\n",
    "    acc_trans=pd.concat(acc_transframes, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f3ed2ad-1e0b-4a8a-88cb-8c832e0c9f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'cc_trans' in locals() and 'acc_trans' in locals():\n",
    "    if debugging: f.write(\"merge cc and acc\")\n",
    "    all_trans = cc_trans.merge(acc_trans, on=['Date','Reference Number','Description','Amount','account','fname'],how='outer')\n",
    "elif 'cc_trans' in locals():\n",
    "    if debugging: f.write(\"cc only\")\n",
    "    all_trans = cc_trans\n",
    "elif 'acc_trans' in locals():\n",
    "    if debugging: f.write(\"acc only\")\n",
    "    all_trans = acc_trans\n",
    "else:\n",
    "    if debugging: f.write(\"no files found\")\n",
    "    raise Exception(\"no files\")\n",
    "\n",
    "if debugging: \n",
    "    cc_trans.to_csv('cc_trans.csv', index=False)\n",
    "    acc_trans.to_csv('acc_trans.csv', index=False)\n",
    "    all_trans.to_csv('all_trans_merged.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6224f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique transactions in the Name / Description column\n",
    "unique_transactions = all_trans[\"Description\"].unique()\n",
    "unique_transactions_df = pd.DataFrame(unique_transactions,columns=['col1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9db916b-83c5-4bdd-b14e-21c10d08dc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get index list\n",
    "#https://stackoverflow.com/questions/47518609/for-loop-range-and-interval-how-to-include-last-step\n",
    "def hop(start, stop, step):\n",
    "    for i in range(start, stop, step):\n",
    "        yield i\n",
    "    yield stop\n",
    "\n",
    "#index_list = list(hop(0, len(unique_transactions), 10))\n",
    "index_list = list(hop(0, len(all_trans), 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e1a6670-1226-4194-8846-b9441a213176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output validation\n",
    "from pydantic import BaseModel, field_validator\n",
    "from typing import List\n",
    "\n",
    "# Validate response format - check if it actually contains hyphen (\"-\")\n",
    "class ResponseChecks(BaseModel):\n",
    "    data: List[str]\n",
    "\n",
    "    @field_validator(\"data\")\n",
    "    def check(cls, value):\n",
    "        for item in value:\n",
    "            if len(item) > 0:\n",
    "                assert \"-\" in item, \"String does not contain hyphen.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d696a58e-2785-497a-92b7-6b21950a8f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_trans(categories_df,all_trans,cnt_trans):\n",
    "    #print('check_trans')\n",
    "    \n",
    "    common_trans= pd.DataFrame()\n",
    "    common_trans = categories_df['Transaction'].str.lower().isin(all_trans['Description'].str.lower())\n",
    "\n",
    "    if np.any(~common_trans):\n",
    "        if debugging: f.write(\"fail on cat vs all trans\")\n",
    "        return False\n",
    "\n",
    "    \n",
    "    if cnt_trans != len(categories_df.index):\n",
    "        if debugging: f.write(\"fail on len\")\n",
    "        return False\n",
    "\n",
    "    if debugging: f.write(\"passing true\")\n",
    "    return True\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d145d357-9589-490a-8619-5d62bc9de272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_transactions(transaction_names):\n",
    "    #print(\"categorzing...\")\n",
    "    llm = Ollama(model=\"llama3test:8b\")\n",
    "    \n",
    "    llm.__init__\n",
    "    response = llm.invoke(\"\"\"\n",
    "    Provide a category for a list of transactions. \n",
    "    some expenses include just the business name, some include the name and part or all of their address, and some include a confirmation number.\n",
    "    For example I will privde :\n",
    "    CVSPHARMACY 123 Somehwer NJ, Spotify AB by Adyen, Beta Boulders Ams Amsterdam Nl,Zelle payment to Bob Manperson Conf o74gqbnm01, CITY OF GOTHAM NJ BILL PAYMENT\n",
    "    Your response should follow these rules:\n",
    "    No further explanation or any other text outside of the transactions and their corresponding categories. \n",
    "    Do not prepend the answer.\n",
    "    Do not edit the transaction text in any way. \n",
    "    Do not add spacing if there are words together. \n",
    "    Do not add or remove any letters. \n",
    "    Do not spell check or alter the text in anyway. \n",
    "    Do not remove the confirmation id from the string. \n",
    "    transactions are separated by ,\n",
    "    The response should be formatted as follows, with one entry and category per line:\n",
    "    CVSPHARMACY 123 Somehwer NJ - Pharmacy\n",
    "    Spotify AB by Adyen - Subscription/Music/Entertainment\n",
    "    Beta Boulders Ams Amsterdam Nld - Gym/Sports\n",
    "    Zelle payment to Bob Manperson Conf o74gqbnm01 - Zelle Payment/Misc\n",
    "    CITY OF GOTHAM NJ BILL PAYMENT - Utilities\n",
    "    Here is my list of transactions:\"\"\" + transaction_names)\n",
    "    response = response.split('\\n')\n",
    "    if debugging: \n",
    "        f.write('transaction_names\\n')\n",
    "        f.write(transaction_names)\n",
    "        f.write('\\n')\n",
    "        f.write('response\\n')\n",
    "        for resp in response:\n",
    "            f.write(resp)\n",
    "            f.write('\\n')\n",
    "    \n",
    "    ResponseChecks(data = response)\n",
    "\n",
    "    \n",
    "    # Put in dataframe\n",
    "    categories_df = pd.DataFrame({'Transaction vs category': response})\n",
    "    categories_df[['Transaction', 'Category']] = categories_df['Transaction vs category'].str.strip().str.split(' - ', expand=True)\n",
    "    #print(categories_df)    \n",
    "    return categories_df, response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548fb822-93bf-4519-b859-9387ec095399",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4599f2f0-c0a7-41e8-b557-64a1ec509fbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Intialise the categories_df_all dataframe\n",
    "categories_df_all = pd.DataFrame()\n",
    "   \n",
    "# Loop through the index_list\n",
    "for i in range(0, len(index_list)-1):\n",
    "    fcnt=0\n",
    "    passed=0\n",
    "    cnt=0\n",
    "    while(not passed and fcnt <3 and cnt < 4):\n",
    "        categories_df= pd.DataFrame()\n",
    "        transaction_names_lst = unique_transactions[index_list[i]:index_list[i+1]]\n",
    "        transaction_names = ','.join(transaction_names_lst)\n",
    "        cnt = cnt +1\n",
    "        \n",
    "        if len(transaction_names_lst):\n",
    "            categories_df,response = categorize_transactions(transaction_names)\n",
    "            if check_trans(categories_df,all_trans,len(transaction_names_lst)):\n",
    "               passed = 1\n",
    "            else:\n",
    "                fcnt= fcnt + 1\n",
    "                \n",
    "    categories_df_all = pd.concat([categories_df_all, categories_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2db6f02-e4a1-4115-9125-58eefdf0d262",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80ac601a-2a96-4522-baa9-0ba2cbbcdd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique categories in categories_df_all\n",
    "unique_categories = categories_df_all[\"Category\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "563a50c3-be3d-4e39-988b-a0ab86e1c210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NA values\n",
    "categories_df_all_no_na = categories_df_all.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd2b344a-f004-400d-a239-13714683da39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the categories_df_all with the transactions_2022_2023.csv dataframe (df)\n",
    "all_trans = pd.merge(all_trans, categories_df_all_no_na, left_on='Description', right_on='Transaction', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e80011d-e45f-4d8a-b8f2-9419679eb613",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trans.to_csv('all_trans_end.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d2fdcf-23d4-44eb-ae81-e0dae5048868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a4d16d-a131-4210-a628-c8b260205a30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6217c666-d741-4622-8224-126a0d16adc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
